{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogisRegression(object):\n",
    "    def __init__(self, score=100, step=0.01):\n",
    "        \"\"\"\n",
    "        param: score: 循环次数\n",
    "        param: step: 步长\n",
    "        \"\"\"\n",
    "        self.score = score\n",
    "        self.step = step\n",
    "        self.w = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        param: X: 特征集\n",
    "        param: y: 结果集\n",
    "        return: self\n",
    "        \"\"\"\n",
    "        self.w = np.ones(X.shape[1] + 1)\n",
    "        self.cost_ = []\n",
    "        for _ in range(self.score):\n",
    "            output = self.set_out_put(X)\n",
    "            errors = y - output\n",
    "            self.w[:-1] += X.T.dot(errors) * self.step\n",
    "            self.w[-1] += errors.sum() * self.step\n",
    "            cost = (errors ** 2).sum() / 2\n",
    "            self.cost_.append(cost)\n",
    "            print(self.w, self.predict(X), cost)\n",
    "    \n",
    "    def logistic(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def set_out_put(self, X):\n",
    "        return X.dot(self.w[:-1].T) + self.w[-1]\n",
    "    \n",
    "    def \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"预测模型\"\"\"\n",
    "        return np.where(self.logistic(X) >= 0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98  0.99  0.99  0.96] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.96  0.98  0.98  0.92] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.94  0.97  0.97  0.88] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.92  0.96  0.96  0.84] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.9   0.95  0.95  0.8 ] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.88  0.94  0.94  0.76] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.86  0.93  0.93  0.72] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.84  0.92  0.92  0.68] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.82  0.91  0.91  0.64] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.8  0.9  0.9  0.6] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.78  0.89  0.89  0.56] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.76  0.88  0.88  0.52] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.74  0.87  0.87  0.48] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.72  0.86  0.86  0.44] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.7   0.85  0.85  0.4 ] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.68  0.84  0.84  0.36] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.66  0.83  0.83  0.32] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.64  0.82  0.82  0.28] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.62  0.81  0.81  0.24] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.6  0.8  0.8  0.2] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.58  0.79  0.79  0.16] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.56  0.78  0.78  0.12] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.54  0.77  0.77  0.08] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.52  0.76  0.76  0.04] [1 1 1 1 1 1 1 1] 2.0\n",
      "[  5.00000000e-01   7.50000000e-01   7.50000000e-01  -3.46944695e-16] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.48  0.74  0.74 -0.04] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.46  0.73  0.73 -0.08] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.44  0.72  0.72 -0.12] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.42  0.71  0.71 -0.16] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.4  0.7  0.7 -0.2] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.38  0.69  0.69 -0.24] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.36  0.68  0.68 -0.28] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.34  0.67  0.67 -0.32] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.32  0.66  0.66 -0.36] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.3   0.65  0.65 -0.4 ] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.28  0.64  0.64 -0.44] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.26  0.63  0.63 -0.48] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.24  0.62  0.62 -0.52] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.22  0.61  0.61 -0.56] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.2  0.6  0.6 -0.6] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.18  0.59  0.59 -0.64] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.16  0.58  0.58 -0.68] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.14  0.57  0.57 -0.72] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.12  0.56  0.56 -0.76] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.1   0.55  0.55 -0.8 ] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.08  0.54  0.54 -0.84] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.06  0.53  0.53 -0.88] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.04  0.52  0.52 -0.92] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ 0.02  0.51  0.51 -0.96] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ -6.17561557e-16   5.00000000e-01   5.00000000e-01  -1.00000000e+00] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.02  0.49  0.49 -1.04] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.04  0.48  0.48 -1.08] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.06  0.47  0.47 -1.12] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.08  0.46  0.46 -1.16] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.1   0.45  0.45 -1.2 ] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.12  0.44  0.44 -1.24] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.14  0.43  0.43 -1.28] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.16  0.42  0.42 -1.32] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.18  0.41  0.41 -1.36] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.2  0.4  0.4 -1.4] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.22  0.39  0.39 -1.44] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.24  0.38  0.38 -1.48] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.26  0.37  0.37 -1.52] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.28  0.36  0.36 -1.56] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.3   0.35  0.35 -1.6 ] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.32  0.34  0.34 -1.64] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.34  0.33  0.33 -1.68] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.36  0.32  0.32 -1.72] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.38  0.31  0.31 -1.76] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.4  0.3  0.3 -1.8] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.42  0.29  0.29 -1.84] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.44  0.28  0.28 -1.88] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.46  0.27  0.27 -1.92] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.48  0.26  0.26 -1.96] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.5   0.25  0.25 -2.  ] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.52  0.24  0.24 -2.04] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.54  0.23  0.23 -2.08] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.56  0.22  0.22 -2.12] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.58  0.21  0.21 -2.16] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.6  0.2  0.2 -2.2] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.62  0.19  0.19 -2.24] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.64  0.18  0.18 -2.28] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.66  0.17  0.17 -2.32] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.68  0.16  0.16 -2.36] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.7   0.15  0.15 -2.4 ] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.72  0.14  0.14 -2.44] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.74  0.13  0.13 -2.48] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.76  0.12  0.12 -2.52] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.78  0.11  0.11 -2.56] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.8  0.1  0.1 -2.6] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.82  0.09  0.09 -2.64] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.84  0.08  0.08 -2.68] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.86  0.07  0.07 -2.72] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.88  0.06  0.06 -2.76] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.9   0.05  0.05 -2.8 ] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.92  0.04  0.04 -2.84] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.94  0.03  0.03 -2.88] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.96  0.02  0.02 -2.92] [1 1 1 1 1 1 1 1] 2.0\n",
      "[-0.98  0.01  0.01 -2.96] [1 1 1 1 1 1 1 1] 2.0\n",
      "[ -1.00000000e+00  -7.52869989e-16  -7.52869989e-16  -3.00000000e+00] [1 1 1 1 1 1 1 1] 2.0\n"
     ]
    }
   ],
   "source": [
    "X = np.array([\n",
    "    [1,1,1],\n",
    "    [1,0,0],\n",
    "    [1,0,1],\n",
    "    [0,1,1],\n",
    "    [1,0,0],\n",
    "    [1,0,1],\n",
    "    [0,1,0],\n",
    "    [0,0,0],\n",
    "])\n",
    "y = np.array([1,1,1,1,0,0,0,0])\n",
    "lr = LogisRegression()\n",
    "lr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.  1.]\n",
      "[[1 1 1]\n",
      " [1 1 0]\n",
      " [1 0 1]\n",
      " [0 1 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 0]]\n",
      "[ 4.  3.  3.  3.  2.  2.  2.  1.]\n"
     ]
    }
   ],
   "source": [
    "w1 = np.ones(X.shape[1] + 1)\n",
    "print(w1)\n",
    "print(X)\n",
    "print(X.dot(w1[:-1].T) + w1[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(y > 0, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
