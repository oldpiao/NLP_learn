{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#目录\n",
    "(序言)* (# sec-preamble)\n",
    "*[第0部分-导入、共享功能和通用代码](#sec-0)\n",
    "*(进口)(# subsec-imports)\n",
    "*(共享功能)(# subsec-shared)\n",
    "*(公共代码)(# subsec-common)\n",
    "*[第1部分-机器学习简介](# sec1)\n",
    "*(第1部分。a -随机森林回归因子](# subsecl -1a)\n",
    "*[第2部分-中间机器学习-缺失值](# sec2)\n",
    "*(第2部分。a -缺失值(丢失值)](#subsec-2a)\n",
    "*(第2部分。b -缺失值(简单Imputation)](#subsec-2b)\n",
    "*[第2部分-缺失值(扩展Imputation)](# subsecl -2c)\n",
    "*[第3部分-中间机器学习-分类变量](#sec-3)\n",
    "*(第3部分。a -分类变量(删除分类变量)](# subsecl -3a)\n",
    "*(第3部分。b -分类变量(标签编码)](#subsec-3b)\n",
    "*[第3部分-分类变量(单热编码)](#subsec-3c)\n",
    "*[第4部分-中间机器学习-管道](# secl -4)\n",
    "*[第5部分-中间机器学习-交叉验证](# secl -5)\n",
    "*[第6部分-中级机器学习- XGBoost](# secl -6)\n",
    "*(第6部分。a - XGBoost(梯度推进)](# subseco -6a)\n",
    "*(第6部分。b - XGBoost(参数调优)](#subsec-6b)\n",
    "*[第7部分-数据可视化](# secl -7)\n",
    "*[第8部分-生成提交](# seco -8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec-preamble\"></a>\n",
    "# **Preamble**\n",
    "\n",
    "This is meant to be a rolling notebook where we analyze the \"House Prices: Advanced Regression Techniques\" dataset using the techniques learned in the coursers offered by Kaggle. Currently the following courses have been completed:\n",
    "1. Python\n",
    "2. Intro to Machine Learning\n",
    "3. Intermediate Machine Learning\n",
    "4. Data Visualization\n",
    "\n",
    "Currently in progress:\n",
    "1. Pandas\n",
    "\n",
    "While I have previous experience in some of these courses, I will try to only update this notebook with concepts/ideas introduced in the courses.\n",
    "\n",
    "## **Goals**\n",
    "\n",
    "The goal of the analysis is to predict the sale value of each house. For a given ID in the test set we want to predict the SalePrice value generated from the training set.\n",
    "\n",
    "## **Notes**\n",
    "\n",
    "This notebook is updated after each course is finished.\n",
    "\n",
    "* The imports in part 1 were commented out and moved to a combined part 0 section\n",
    "* Shared code such as the reading in of data was consoldated into part 0\n",
    "* The most effective ML method was the XGBoost method using parameter tuning. This results in a score of 0.13719 which is top 42% of scores.\n",
    "* Due to the order the courses were taken in, the data visualization will come _AFTER_ the intermediate ML which doesn't make much practical sense. In principle one would use data visualization to perform a feature exploration and determine which properties are relevant to their analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec-0\"></a>\n",
    "# **Part 0. Imports, Shared Functions and Common Code**\n",
    "\n",
    "After finishing the intermediate course it became clear that having a combined section for imports and any shared functions would be best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"subsec-imports\"></a>\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports used throughout the notebook\n",
    "\n",
    "# plotting packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# packages needed for introductory ML\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# packages needed for intermediate ML\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Others\n",
    "import numpy as np\n",
    "\n",
    "print(\"Finished Imports\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"subsec-shared\"></a>\n",
    "## Shared Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MAE(X_train, X_valid, y_train, y_valid):\n",
    "    \"\"\"\n",
    "    Calculates the mean absolute error (MAE) for a ML approach\n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    X_train:\n",
    "        the training data used\n",
    "    X_valid:\n",
    "        the data to be compared to\n",
    "    y_train:\n",
    "        the y values that are used for training the model\n",
    "    y_valid:\n",
    "        the y values we want our comparison to be tested against\n",
    "    \n",
    "    Output:\n",
    "    -------\n",
    "    mean_absolute_error:\n",
    "        sum of total absolute error divided by sample size\n",
    "    \"\"\"\n",
    "    \n",
    "    model = RandomForestRegressor(n_estimators=100)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_predict = model.predict(X_valid)\n",
    "    mae = mean_absolute_error(y_valid, y_predict)\n",
    "    return mae\n",
    "\n",
    "def get_score(n_estimators, X, y):\n",
    "    \"\"\"\n",
    "    Return the average MAE over 3 CV folds of random forest model.\n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    n_estimators:\n",
    "        the number of trees in the forest\n",
    "        \n",
    "    Output:\n",
    "    -------\n",
    "    mean_score:\n",
    "        The mean scores when using a pipeline to determine the mean absolute error\n",
    "    \"\"\"\n",
    "    # Replace this body with your own code\n",
    "    pipeline = Pipeline(steps=[('preprocessor', SimpleImputer()),\n",
    "                               ('model', RandomForestRegressor(n_estimators, random_state=0))])\n",
    "    scores = -1 * cross_val_score(pipeline, X, y, cv=3, scoring='neg_mean_absolute_error')\n",
    "    return scores.mean()\n",
    "\n",
    "def gen_prediction(training_data, target_data, test_data, estimators=100):\n",
    "    \"\"\"\n",
    "    Calculate the model prediction using an inputted training, target and\n",
    "    test data.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    training_data:\n",
    "        training data in a pandas array used to generate a model\n",
    "    target_data:\n",
    "        target data in a pandas array used to generate a model\n",
    "    test_data: \n",
    "        test data we will be fitting a model to\n",
    "    \n",
    "    Output:\n",
    "    -------\n",
    "    predictions for test data\n",
    "    \"\"\"\n",
    "    # Define and fit model\n",
    "    my_model = RandomForestRegressor(n_estimators=estimators, random_state=0)\n",
    "    my_model.fit(training_data, target_data)\n",
    "\n",
    "    # Get test predictions\n",
    "    print (\"Submission data calculated\")\n",
    "    return my_model.predict(test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"subsec-common\"></a>\n",
    "## Common Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the paths to our data\n",
    "test_data_path = \"../input/house-prices-advanced-regression-techniques/test.csv\"\n",
    "train_data_path = \"../input/house-prices-advanced-regression-techniques/train.csv\"\n",
    "sample_data_path = \"../input/house-prices-advanced-regression-techniques/sample_submission.csv\"\n",
    "\n",
    "# Define the data\n",
    "test_data = pd.read_csv(test_data_path, index_col='Id')\n",
    "train_data = pd.read_csv(train_data_path, index_col='Id')\n",
    "sample_data = pd.read_csv(sample_data_path)\n",
    "\n",
    "# Create a directory to hold the scores of each part with different techniques\n",
    "scores_dict = {}\n",
    "submission_dict = {}\n",
    "\n",
    "print(\"Data loaded and dictionaries initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick data property checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the head of each file\n",
    "test_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the shape of our test, train, and sample data\n",
    "print(\"Training data shape: {}\".format(train_data.shape))\n",
    "print(\"Testing data shape: {}\".format(test_data.shape))\n",
    "print(\"Sample data shape: {}\".format(sample_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec-1\"></a>\n",
    "# **Part 1. Intro to Machine Learning**\n",
    "<a id=\"subsec-1a\"></a>\n",
    "## Part 1.a Using a Random Forest Regressor\n",
    "* This first submission is unlikely to score very highly as we are only using simple techniques but its a good place to start.\n",
    "* This submission scored 0.18806 which in the top 79%, we can definitely improve on this score with more advanced analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test using Random Forest Regressor\n",
    "This is the simplest approach, I wont include the attempts using other methods from the intro course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data for testing\n",
    "y = train_data.SalePrice\n",
    "X = train_data.drop(['SalePrice'], axis=1)\n",
    "\n",
    "# Divide our data into training and validation data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define properties that are useful from the intro course\n",
    "features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "X_train_features = X_train[features]\n",
    "X_valid_features = X_valid[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the MAE of this model\n",
    "scores_dict['1.a'] = get_MAE(X_train_features, X_valid_features, y_train, y_valid)\n",
    "\n",
    "print(\"MAE of simple Random Forest Regressor: \")\n",
    "print(scores_dict['1.a'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the Submission using Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a target object\n",
    "train_y = train_data.SalePrice\n",
    "\n",
    "# Define properties that are useful from the intro course\n",
    "features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "train_X = train_data[features]\n",
    "test_X = test_data[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction on the values using RandomForestRegressor\n",
    "test_prediction_1a = gen_prediction(train_X, train_y, test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the data together into an output and save it to submission.csv\n",
    "output = pd.DataFrame({'Id': test_X.index,\n",
    "                       'SalePrice': test_prediction_1a})\n",
    "submission_dict['1.a'] = test_prediction_1a\n",
    "print(\"Random Forest Regressor Submission Saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec-2\"></a>\n",
    "# **Part 2.Intermediate Machine Learning - Missing Data**\n",
    "* This section will contain predictions done using the techniques taught in the missing data portion intermediate machine learning course\n",
    "* The score using these techniques was 0.14855 which is in the top 58%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data that will be used for all tests\n",
    "y = train_data.SalePrice\n",
    "X_full = train_data.drop(['SalePrice'], axis=1)\n",
    "\n",
    "# To keep things simple, we'll use only numerical predictors\n",
    "X = X_full.select_dtypes(exclude=['object'])\n",
    "\n",
    "# Break off validation set from training data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)\n",
    "\n",
    "# Define the data that will be used for all submission generation\n",
    "X_test = test_data.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"subsec-2a\"></a>\n",
    "## Part 2.a Missing Values (Dropping values)\n",
    "This section will use the approach where we simply drop any columns missing data\n",
    "## Test the effectiveness of dropping values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in each column of training data\n",
    "missing_val_train = [column for column in X_train.columns\n",
    "                     if X_train[column].isnull().any()]\n",
    "print(missing_val_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns in training and validation data\n",
    "reduced_X_train = X_train.drop(missing_val_train, axis=1)\n",
    "reduced_X_valid = X_valid.drop(missing_val_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the MAE of this model\n",
    "scores_dict['2.a'] = get_MAE(reduced_X_train, reduced_X_valid, y_train, y_valid)\n",
    "\n",
    "print(\"MAE (Drop columns with missing values):\")\n",
    "print(scores_dict['2.a'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the submission dropping missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in each column of training data and test data using list comprehension\n",
    "missing_val_X = [column for column in X.columns\n",
    "                 if X[column].isnull().any()]\n",
    "\n",
    "missing_val_X_test = [column for column in X_train.columns\n",
    "                      if X_test[column].isnull().any()]\n",
    "\n",
    "print(\"Columns with missing training data: \")\n",
    "print(missing_val_X)\n",
    "\n",
    "print(\"\\nColumns with missing test data: \")\n",
    "print(missing_val_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the two sets of missing columns together\n",
    "# If we combine the two sets of missing columns together arbitrarily we'll get duplicates\n",
    "print(missing_val_X + missing_val_X_test)\n",
    "\n",
    "combined_missing_val = list(set(missing_val_X + missing_val_X_test))\n",
    "print(combined_missing_val)\n",
    "\n",
    "print(\"\\nTotal number of columns to be dropped:\")\n",
    "print(len(combined_missing_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the missing values in both sets\n",
    "X_drop = X.drop(combined_missing_val, axis=1)\n",
    "X_test_drop = X_test.drop(combined_missing_val, axis=1)\n",
    "\n",
    "print (\"Shape of X_train: {}\".format(X.shape))\n",
    "print (\"Shape of X_test: {}\".format(X_test.shape))\n",
    "\n",
    "print (\"Shape of X_train_drop: {}\".format(X_drop.shape))\n",
    "print (\"Shape of X_test_drop: {}\".format(X_test_drop.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the predictions\n",
    "test_prediction_2a = gen_prediction(X_drop, y, X_test_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the data together into an output and save it to submission.csv\n",
    "output = pd.DataFrame({'Id': test_X.index,\n",
    "                       'SalePrice': test_prediction_2a})\n",
    "submission_dict['2.a'] = test_prediction_2a\n",
    "print(\"Drop Value Submission Saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"subsec-2b\"></a>\n",
    "## Part 2.b Missing Values (Simple Imputation)\n",
    "This section will use the approach where we use imputation to fill in missing data\n",
    "## Test the effectiveness of simple imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation, setup the simple imputer and apply it to our training data\n",
    "my_imputer = SimpleImputer()\n",
    "imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
    "imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n",
    "\n",
    "# imputation removed column names; put them back\n",
    "imputed_X_train.columns = X_train.columns\n",
    "imputed_X_valid.columns = X_valid.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the MAE of this model\n",
    "scores_dict['2.b'] = get_MAE(imputed_X_train, imputed_X_valid, y_train, y_valid)\n",
    "\n",
    "print(\"MAE (Imputation):\")\n",
    "print(scores_dict['2.b'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the output for simple imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation, setup the simple imputer and apply it to our full data\n",
    "my_imputer = SimpleImputer()\n",
    "imputed_X = pd.DataFrame(my_imputer.fit_transform(X))\n",
    "imputed_X_test = pd.DataFrame(my_imputer.transform(X_test))\n",
    "\n",
    "# imputation removed column names; put them back\n",
    "imputed_X.columns = X.columns\n",
    "imputed_X_test.columns = X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the predictions\n",
    "test_prediction_2b = gen_prediction(imputed_X, y, imputed_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the data together into an output and save it to submission.csv\n",
    "output = pd.DataFrame({'Id': test_X.index,\n",
    "                       'SalePrice': test_prediction_2b})\n",
    "submission_dict['2.b'] = test_prediction_2b\n",
    "print(\"Simple Imputation Submission Saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"subsec-2c\"></a>\n",
    "## Part 2.c Missing Values (Extended Imputation)\n",
    "In this section we will try to extend the simple imputation by only working on the columns with missing data\n",
    "## Test the effectiveness of extended imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard copy the data to ensure that we don't change the original\n",
    "X_train_ext = X_train.copy()\n",
    "X_valid_ext = X_valid.copy()\n",
    "\n",
    "# Use the missing columns found in section 2.a, reminder of how these\n",
    "# columns were found\n",
    "# missing_column = [col for col in X_train.columns\n",
    "#                   if X_train[col].isnull().any()]\n",
    "\n",
    "# generate new columns we want to impute\n",
    "for column in missing_val_train:\n",
    "    X_train_ext[column + '_missing'] = X_train_ext[column].isnull()\n",
    "    X_valid_ext[column + '_missing'] = X_valid_ext[column].isnull()\n",
    "    \n",
    "# impute the extended data\n",
    "# Imputation, setup the simple imputer and apply it to our full data\n",
    "my_imputer = SimpleImputer()\n",
    "imputed_X_train_ext = pd.DataFrame(my_imputer.fit_transform(X_train_ext))\n",
    "imputed_X_valid_ext = pd.DataFrame(my_imputer.transform(X_valid_ext))\n",
    "\n",
    "# imputation removed column names; put them back\n",
    "imputed_X_train_ext.columns = X_train_ext.columns\n",
    "imputed_X_valid_ext.columns = X_valid_ext.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the MAE of this model\n",
    "scores_dict['2.c'] = get_MAE(imputed_X_train_ext, imputed_X_valid_ext, y_train, y_valid)\n",
    "\n",
    "print(\"MAE (Extended Imputation):\")\n",
    "print(scores_dict['2.c'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the output for extended imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard copy the data to ensure that we don't change the original\n",
    "X_ext = X.copy()\n",
    "X_test_ext = X_test.copy()\n",
    "\n",
    "# Use the missing columns found in section 2.a, reminder of how these\n",
    "# columns were found\n",
    "# missing_column = [col for col in X_train.columns\n",
    "#                   if X_train[col].isnull().any()]\n",
    "\n",
    "# generate new columns we want to impute\n",
    "for column in combined_missing_val:\n",
    "    X_ext[column + '_missing'] = X_ext[column].isnull()\n",
    "    X_test_ext[column + '_missing'] = X_test_ext[column].isnull()\n",
    "    \n",
    "# impute the extended data\n",
    "# Imputation, setup the simple imputer and apply it to our full data\n",
    "my_imputer = SimpleImputer()\n",
    "imputed_X_ext = pd.DataFrame(my_imputer.fit_transform(X_ext))\n",
    "imputed_X_test_ext = pd.DataFrame(my_imputer.transform(X_test_ext))\n",
    "\n",
    "# imputation removed column names; put them back\n",
    "imputed_X_ext.columns = X_ext.columns\n",
    "imputed_X_test_ext.columns = X_test_ext.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the predictions\n",
    "test_prediction_2c = gen_prediction(imputed_X_ext, y, imputed_X_test_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the data together into an output and save it to submission.csv\n",
    "output = pd.DataFrame({'Id': test_X.index,\n",
    "                       'SalePrice': test_prediction_2c})\n",
    "submission_dict['2.c'] = test_prediction_2c\n",
    "print(\"Extended Imputation Submission Saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec-3\"></a>\n",
    "# **Part 3. Intermediate Machine Learning - Categorical Variables**\n",
    "This section will contain predictions done using the techniques taught in the intermediate machine learning course in regards to dealing with categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data that will be used for all tests\n",
    "y = train_data.SalePrice\n",
    "X = train_data.drop(['SalePrice'], axis=1)\n",
    "\n",
    "# Define the data that will be used for all submission generation\n",
    "X_test = test_data.copy()\n",
    "\n",
    "# Break off validation set from training data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y,\n",
    "                                                      train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"subsec-3a\"></a>\n",
    "## Part 3.a Categorical Variables (Drop Categorical Variables)\n",
    "This section will use the approach where we just drop categorical variables\n",
    "## Test the effectiveness of dropping variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in each column of training data\n",
    "missing_val_train = [column for column in X_train.columns\n",
    "                     if X_train[column].isnull().any()]\n",
    "\n",
    "# drop columns in training and validation data\n",
    "reduced_X_train = X_train.drop(missing_val_train, axis=1)\n",
    "reduced_X_valid = X_valid.drop(missing_val_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Shape of X_train: {}\".format(X_train.shape))\n",
    "print (\"Shape of X_valid: {}\".format(X_valid.shape))\n",
    "\n",
    "print (\"Shape of reduced_X_train: {}\".format(reduced_X_train.shape))\n",
    "print (\"Shape of reduced_X_valid: {}\".format(reduced_X_valid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the objects from our dataset\n",
    "drop_X_train = reduced_X_train.select_dtypes(exclude=['object'])\n",
    "drop_X_valid = reduced_X_valid.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Shape of drop_X_train: {}\".format(drop_X_train.shape))\n",
    "print (\"Shape of drop_X_valid: {}\".format(drop_X_valid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the MAE of this model\n",
    "scores_dict['3.a'] = get_MAE(drop_X_train, drop_X_valid, y_train, y_valid)\n",
    "\n",
    "print(\"MAE (Drop categorical variables):\")\n",
    "print(scores_dict['3.a'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the output for dropping variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in each column of training data and test data using list comprehension\n",
    "# This is taken from section 2.a for finding columns with missing data\n",
    "missing_val_X = [column for column in X.columns\n",
    "                 if X[column].isnull().any()]\n",
    "\n",
    "missing_val_X_test = [column for column in X_train.columns\n",
    "                      if X_test[column].isnull().any()]\n",
    "\n",
    "combined_missing_val = list(set(missing_val_X + missing_val_X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns in training and validation data\n",
    "reduced_X = X.drop(combined_missing_val, axis=1)\n",
    "reduced_X_test = X_test.drop(combined_missing_val, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Shape of X: {}\".format(X.shape))\n",
    "print (\"Shape of X_test: {}\".format(X_test.shape))\n",
    "\n",
    "print (\"Shape of reduced_X: {}\".format(reduced_X.shape))\n",
    "print (\"Shape of reduced_X_test: {}\".format(reduced_X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the objects from our dataset\n",
    "drop_X = reduced_X.select_dtypes(exclude=['object'])\n",
    "drop_X_test = reduced_X_test.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Shape of drop_X: {}\".format(drop_X.shape))\n",
    "print (\"Shape of drop_X_test: {}\".format(drop_X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the predictions\n",
    "test_prediction_3a = gen_prediction(drop_X, y, drop_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the data together into an output and save it to submission.csv\n",
    "output = pd.DataFrame({'Id': test_X.index,\n",
    "                       'SalePrice': test_prediction_3a})\n",
    "submission_dict['3.a'] = test_prediction_3a\n",
    "print(\"Drop Variable Submission Saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"subsec-3b\"></a>\n",
    "## Part 3.b Categorical Variables (Label Encoding)\n",
    "This section will use the approach where we assign a unique value to a different integer\n",
    "## Test the effectiveness of converting labels to integer values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All categorical columns\n",
    "object_cols = [column for column in X_train.columns if\n",
    "               X_train[column].dtype == \"object\"]\n",
    "\n",
    "# Columns that can be safely label encoded\n",
    "good_label_cols = [column for column in object_cols if \n",
    "                   set(X_train[column]) == set(X_valid[column])]\n",
    "        \n",
    "# Problematic columns that will be dropped from the dataset\n",
    "bad_label_cols = list(set(object_cols) - set(good_label_cols))\n",
    "        \n",
    "print('Categorical columns that will be label encoded:', good_label_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', bad_label_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop categorical columns that will not be encoded\n",
    "label_X_train = X_train.drop(bad_label_cols, axis=1)\n",
    "label_X_valid = X_valid.drop(bad_label_cols, axis=1)\n",
    "\n",
    "print (\"Shape of X_train: {}\".format(X_train.shape))\n",
    "print (\"Shape of X_valid: {}\".format(X_valid.shape))\n",
    "\n",
    "print (\"\\nShape of label_X_train after dropping bad labels: {}\".format(label_X_train.shape))\n",
    "print (\"Shape of label_X_valid after dropping bad labels: {}\".format(label_X_valid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply label encoder \n",
    "# Cannot use the code shown in the course, will raise error:\n",
    "#     TypeError: Encoders require their input to be uniformly strings or numbers. Got ['float', 'str']\n",
    "# For solution:\n",
    "#     https://stackoverflow.com/questions/46406720/labelencoder-typeerror-not-supported-between-instances-of-float-and-str\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "for column in set(good_label_cols):\n",
    "    label_X_train[column] = label_encoder.fit_transform(X_train[column].astype(str))\n",
    "    label_X_valid[column] = label_encoder.transform(X_valid[column].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We cant directly calculate the MAE from this point,\n",
    "# if we do there will be some missing values, need to impute some values\n",
    "imputed_label_X_train = pd.DataFrame(my_imputer.fit_transform(label_X_train))\n",
    "imputed_label_X_valid = pd.DataFrame(my_imputer.transform(label_X_valid))\n",
    "\n",
    "# imputation removed column names; put them back\n",
    "imputed_label_X_train.columns = label_X_train.columns\n",
    "imputed_label_X_valid.columns = label_X_valid.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the MAE of this model\n",
    "scores_dict['3.b'] = get_MAE(imputed_label_X_train, imputed_label_X_valid, y_train, y_valid)\n",
    "\n",
    "print(\"MAE (Label Encoding):\") \n",
    "print(scores_dict['3.b'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the output for label encoding\n",
    "\n",
    "If we directly follow the same steps as above for calculating the MAE we encounter an error where there are remaining NaN in the data set. To solve this we need to split the data into categorical and numerical data and work with them separately. Once we have processed the data in two chunks we can concat them back together then generate the predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All categorical columns\n",
    "object_cols_full = X.columns\n",
    "\n",
    "# Columns that can be safely label encoded\n",
    "good_label_cols_full = [column for column in object_cols_full if \n",
    "                        set(X[column]) == set(X_test[column])]\n",
    "        \n",
    "# Problematic columns that will be dropped from the dataset\n",
    "bad_label_cols_full = list(set(object_cols_full) - set(good_label_cols_full))\n",
    "\n",
    "print('\\nNumber of Categorical columns that will be label encoded:', len(good_label_cols_full))\n",
    "print('Categorical columns that will be label encoded:', good_label_cols_full)\n",
    "\n",
    "print('\\nNumber of categorical columns that will be dropped from the dataset:', len(bad_label_cols_full))\n",
    "print('Categorical columns that will be dropped from the dataset:', bad_label_cols_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the categorical columns and numeric columns\n",
    "cat_X = X[object_cols_full].copy()\n",
    "cat_X_test = X_test[object_cols_full].copy()\n",
    "\n",
    "num_X = X.select_dtypes(exclude=['object']).copy()\n",
    "\n",
    "num_X_test = X_test.select_dtypes(exclude=['object']).copy()\n",
    "\n",
    "# Drop categorical columns that will not be encoded\n",
    "label_cat_X = cat_X.drop(bad_label_cols_full, axis=1)\n",
    "label_cat_X_test = cat_X_test.drop(bad_label_cols_full, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Shape of X: {}\".format(X.shape))\n",
    "print (\"Shape of X_test: {}\".format(X_test.shape))\n",
    "\n",
    "print (\"\\nShape of cat_X: {}\".format(cat_X.shape))\n",
    "print (\"Shape of cat_X_test: {}\".format(cat_X_test.shape))\n",
    "\n",
    "print (\"\\nShape of num_X: {}\".format(num_X.shape))\n",
    "print (\"Shape of num_X_test: {}\".format(num_X_test.shape))\n",
    "\n",
    "print (\"\\nShape of label_cat_X after dropping bad labels: {}\".format(label_cat_X.shape))\n",
    "print (\"Shape of label_cat_X_test after dropping bad labels: {}\".format(label_cat_X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the two different sets of data:\n",
    "\n",
    "# Impute numerical columns\n",
    "num_imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "imputed_num_X = pd.DataFrame(num_imputer.fit_transform(num_X))\n",
    "imputed_num_X_test = pd.DataFrame(num_imputer.transform(num_X_test))\n",
    "\n",
    "# imputation removed column names; put them back\n",
    "imputed_num_X.columns = num_X.columns\n",
    "imputed_num_X_test.columns = num_X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute category columns\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "imputed_label_cat_X = pd.DataFrame(cat_imputer.fit_transform(label_cat_X))\n",
    "imputed_label_cat_X_test = pd.DataFrame(cat_imputer.transform(label_cat_X_test))\n",
    "\n",
    "# imputation removed column names; put them back\n",
    "imputed_label_cat_X.columns = label_cat_X.columns\n",
    "imputed_label_cat_X_test.columns = label_cat_X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply label encoder \n",
    "# Cannot use the code shown in the course, will raise error:\n",
    "#     TypeError: Encoders require their input to be uniformly strings or numbers. Got ['float', 'str']\n",
    "# For solution:\n",
    "#     https://stackoverflow.com/questions/46406720/labelencoder-typeerror-not-supported-between-instances-of-float-and-str\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "for column in set(good_label_cols_full):\n",
    "    imputed_label_cat_X[column] = label_encoder.fit_transform(X[column].astype(str))\n",
    "    imputed_label_cat_X_test[column] = label_encoder.transform(X_test[column].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"\\nShape of imputed_label_cat_X: {}\".format(imputed_label_cat_X.shape))\n",
    "print (\"Shape of imputed_label_cat_X_test: {}\".format(imputed_label_cat_X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_label_X = pd.concat([imputed_num_X, imputed_label_cat_X], axis=1)\n",
    "full_label_X_test = pd.concat([imputed_num_X_test, imputed_label_cat_X_test], axis=1)\n",
    "\n",
    "print (\"\\nShape of full_label_X after merge: {}\".format(full_label_X.shape))\n",
    "print (\"Shape of full_label_X_test after merge: {}\".format(full_label_X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the predictions\n",
    "test_prediction_3b = gen_prediction(full_label_X, y, full_label_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the data together into an output and save it to submission.csv\n",
    "output = pd.DataFrame({'Id': test_X.index,\n",
    "                       'SalePrice': test_prediction_3b})\n",
    "submission_dict['3.b'] = test_prediction_3b\n",
    "print(\"Label Variable Submission Saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"subsec-3c\"></a>\n",
    "## Part 3.c Categorical Variables (One-Hot Encoding)\n",
    "Here we will use one-hot encoding where we create new columns that indicate the presence or absence of values in the original data.\n",
    "## Testing One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate cardinality\n",
    "object_cols = [column for column in X_train.columns if X_train[column].dtype == \"object\"]\n",
    "\n",
    "# Columns that will be one-hot encoded\n",
    "low_cardinality_cols = [column for column in object_cols if X_train[column].nunique() < 10]\n",
    "\n",
    "# Columns that will be dropped from the dataset\n",
    "high_cardinality_cols = list(set(object_cols)-set(low_cardinality_cols))\n",
    "\n",
    "print('Categorical columns that will be one-hot encoded:', low_cardinality_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', high_cardinality_cols)\n",
    "\n",
    "OH_X_train = X_train[low_cardinality_cols]\n",
    "OH_X_valid = X_valid[low_cardinality_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation to categorical columns or we'll encounter problems with NaN\n",
    "# Impute category columns\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "imputed_X_train = pd.DataFrame(cat_imputer.fit_transform(OH_X_train))\n",
    "imputed_X_valid = pd.DataFrame(cat_imputer.transform(OH_X_valid))\n",
    "\n",
    "# imputation removed column names; put them back\n",
    "imputed_X_train.columns = OH_X_train.columns\n",
    "imputed_X_valid.columns = OH_X_valid.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = X_train.drop(object_cols, axis=1)\n",
    "num_X_valid = X_valid.drop(object_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute numerical columns\n",
    "num_imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "imputed_num_X_train = pd.DataFrame(num_imputer.fit_transform(num_X_train))\n",
    "imputed_num_X_valid = pd.DataFrame(num_imputer.transform(num_X_valid))\n",
    "\n",
    "# imputation removed column names; put them back\n",
    "imputed_num_X_train.columns = num_X_train.columns\n",
    "imputed_num_X_valid.columns = num_X_valid.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply one-hot encoder to each column with categorical data\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(imputed_X_train))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(imputed_X_valid))\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = imputed_X_train.index\n",
    "OH_cols_valid.index = imputed_X_valid.index\n",
    "\n",
    "# Add one-hot encoded columns to numerical features\n",
    "OH_X_train = pd.concat([OH_cols_train, imputed_num_X_train], axis=1)\n",
    "OH_X_valid = pd.concat([OH_cols_valid, imputed_num_X_valid], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"\\nShape of num_X_train: {}\".format(num_X_train.shape))\n",
    "print (\"Shape of num_X_valid: {}\".format(num_X_valid.shape))\n",
    "\n",
    "print (\"\\nShape of OH_cols_train: {}\".format(OH_cols_train.shape))\n",
    "print (\"Shape of OH_cols_valid: {}\".format(OH_cols_valid.shape))\n",
    "\n",
    "print (\"\\nShape of OH_X_train after merge: {}\".format(OH_X_train.shape))\n",
    "print (\"Shape of OH_X_valid after merge: {}\".format(OH_X_valid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_dict['3.c'] = get_MAE(OH_X_train, OH_X_valid, y_train, y_valid)\n",
    "\n",
    "print(\"MAE (One-Hot Encoding):\") \n",
    "print(scores_dict['3.c'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the output for One Hot Encoding\n",
    "We can effectively just copy the code for generating the MAE value and change the inputs to take the entire dataset instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate cardinality\n",
    "object_cols_full = [column for column in X.columns if X[column].dtype == \"object\"]\n",
    "\n",
    "# Columns that will be one-hot encoded\n",
    "low_cardinality_cols_full = [column for column in object_cols_full if X[column].nunique() < 10]\n",
    "\n",
    "# Columns that will be dropped from the dataset\n",
    "high_cardinality_cols_full = list(set(object_cols_full)-set(low_cardinality_cols_full))\n",
    "\n",
    "print('Categorical columns that will be one-hot encoded:', low_cardinality_cols_full)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', high_cardinality_cols_full)\n",
    "\n",
    "OH_X = X[low_cardinality_cols_full]\n",
    "OH_X_test = X_test[low_cardinality_cols_full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation to categorical columns or we'll encounter problems with NaN\n",
    "# Impute category columns\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "imputed_X = pd.DataFrame(cat_imputer.fit_transform(OH_X))\n",
    "imputed_X_test = pd.DataFrame(cat_imputer.transform(OH_X_test))\n",
    "\n",
    "# imputation removed column names; put them back\n",
    "imputed_X.columns = OH_X.columns\n",
    "imputed_X_test.columns = OH_X_test.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X = X.drop(object_cols_full, axis=1)\n",
    "num_X_test = X_test.drop(object_cols_full, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute numerical columns\n",
    "num_imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "imputed_num_X = pd.DataFrame(num_imputer.fit_transform(num_X))\n",
    "imputed_num_X_test = pd.DataFrame(num_imputer.transform(num_X_test))\n",
    "\n",
    "# imputation removed column names; put them back\n",
    "imputed_num_X.columns = num_X.columns\n",
    "imputed_num_X_test.columns = num_X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply one-hot encoder to each column with categorical data\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols = pd.DataFrame(OH_encoder.fit_transform(imputed_X))\n",
    "OH_cols_test = pd.DataFrame(OH_encoder.transform(imputed_X_test))\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols.index = imputed_X.index\n",
    "OH_cols_test.index = imputed_X_test.index\n",
    "\n",
    "# Add one-hot encoded columns to numerical features\n",
    "OH_X = pd.concat([OH_cols, imputed_num_X], axis=1)\n",
    "OH_X_test = pd.concat([OH_cols_test, imputed_num_X_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the predictions\n",
    "test_prediction_3c = gen_prediction(OH_X, y, OH_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the data together into an output and save it to submission.csv\n",
    "output = pd.DataFrame({'Id': test_X.index,\n",
    "                       'SalePrice': test_prediction_3c})\n",
    "submission_dict['3.c'] = test_prediction_3c\n",
    "print(\"One-Hot Encoding Submission Saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec-4\"></a>\n",
    "# Part 4. Intermediate Machine Learning - Pipelines\n",
    "This section will demonstrate the use of pipelines. Pipelines won't necessarily improve our MAE score but it does bundle the preprocessing and modelling steps together which will streamline our code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data that will be used for all tests\n",
    "y_full = train_data.SalePrice\n",
    "X_full = train_data.drop(['SalePrice'], axis=1)\n",
    "\n",
    "# Define the data that will be used for all submission generation\n",
    "X_test_full = test_data.copy()\n",
    "\n",
    "# Break off validation set from training data\n",
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X_full, y, \n",
    "                                                                train_size=0.8, test_size=0.2,\n",
    "                                                                random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the effectiveness of pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality\n",
    "categorical_cols = [cname for cname in X_train_full.columns if\n",
    "                    X_train_full[cname].nunique() < 10 and \n",
    "                    X_train_full[cname].dtype == \"object\"]\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols = [cname for cname in X_train_full.columns if \n",
    "                X_train_full[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Keep selected columns only\n",
    "my_cols = categorical_cols + numerical_cols\n",
    "X_train = X_train_full[my_cols].copy()\n",
    "X_valid = X_valid_full[my_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for numerical data\n",
    "# depending on choice of strategy we can get very different MAE values later\n",
    "numerical_transformer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', model)\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing of training data, fit model \n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "preds = clf.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_dict['4.a'] = mean_absolute_error(y_valid, preds)\n",
    "\n",
    "print(\"MAE (Pipeline):\") \n",
    "print(scores_dict['4.a'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the output for pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "categorical_cols_full = [cname for cname in X.columns if\n",
    "                         X[cname].nunique() < 10 and \n",
    "                         X[cname].dtype == \"object\"]\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols_full = [cname for cname in X.columns if \n",
    "                       X[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Keep selected columns only\n",
    "my_cols_full = categorical_cols_full + numerical_cols_full\n",
    "X = X_full[my_cols_full].copy()\n",
    "X_test = X_test_full[my_cols_full].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for numerical data\n",
    "# depending on choice of strategy we can get very different MAE values later\n",
    "numerical_transformer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols_full),\n",
    "        ('cat', categorical_transformer, categorical_cols_full)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', model)\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing of training data, fit model \n",
    "clf.fit(X, y)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "test_prediction_4 = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the data together into an output and save it to submission.csv\n",
    "output = pd.DataFrame({'Id': test_X.index,\n",
    "                       'SalePrice': test_prediction_4})\n",
    "submission_dict['4.a'] = test_prediction_4\n",
    "print(\"Pipeline Submission Saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec-5\"></a>\n",
    "# Part 5. Intermediate Machine Learning - Cross-Validation\n",
    "Machine learning is iterative and is a better way to validate our data, but it shouldn't lead to a strong result without a solid algorithm to start with. For the test portion of this we will still use the full data set and choose the number of estimators that produces the best result for the submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data that will be used for all tests\n",
    "y = train_data.SalePrice\n",
    "X = train_data.drop(['SalePrice'], axis=1)\n",
    "\n",
    "# Define the data that will be used for all submission generation\n",
    "X_test = test_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the column filtering from pipelines\n",
    "categorical_cols = [cname for cname in X.columns if X[cname].nunique() < 10 and \n",
    "                        X[cname].dtype == \"object\"]\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols = [cname for cname in X.columns if X[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Keep selected columns only\n",
    "my_cols = categorical_cols + numerical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter down to the numerical columns\n",
    "cv_X = X[numerical_cols].copy()\n",
    "cv_test = X_test[numerical_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the results\n",
    "results={}\n",
    "for index in range(1, 9):\n",
    "    results[50*index] = get_score(n_estimators=50*index, X=cv_X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results to see where the ideal number of n_estimators is\n",
    "plt.plot(list(results.keys()), list(results.values()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_n_ests = min(results, key=results.get)\n",
    "\n",
    "print(\"n_estimators with lowest score:\")\n",
    "print(min_n_ests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_dict['5.a'] = min(results.values())\n",
    "\n",
    "print(\"MAE (Pipeline):\") \n",
    "print(scores_dict['5.a'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Submission Using Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the pipeline\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model with the n_estimators with lowest score\n",
    "model = RandomForestRegressor(n_estimators=min_n_ests, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing of training data, fit model \n",
    "cv_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('model', model)\n",
    "                             ])\n",
    "cv_X = X[my_cols].copy()\n",
    "cv_X_test = X_test[my_cols].copy()\n",
    "cv_pipeline.fit(cv_X, y)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "test_prediction_5 = cv_pipeline.predict(cv_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the data together into an output and save it to submission.csv\n",
    "output = pd.DataFrame({'Id': test_X.index,\n",
    "                       'SalePrice': test_prediction_5})\n",
    "submission_dict['5.a'] = test_prediction_5\n",
    "print(\"Cross Validation Submission Saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec-6\"></a>\n",
    "# Part 6. Intermediate Machine Learning - XGBoost\n",
    "In all of our previous sections we have been using random forest, here we will be using a different method called gradient boosting. This method should yield much better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data that will be used for all tests\n",
    "y_full = train_data.SalePrice\n",
    "X_full = train_data.drop(['SalePrice'], axis=1)\n",
    "\n",
    "# Define the data that will be used for all submission generation\n",
    "X_test_full = test_data.copy()\n",
    "\n",
    "# Break off validation set from training data\n",
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X_full, y, \n",
    "                                                                train_size=0.8, test_size=0.2,\n",
    "                                                                random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"subsec-6a\"></a>\n",
    "## Part 6.a XGBoost (Gradient Boost)\n",
    "## Testing the effectiveness of Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "low_cardinality_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and \n",
    "                        X_train_full[cname].dtype == \"object\"]\n",
    "\n",
    "# Select numeric columns\n",
    "numeric_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Keep selected columns only\n",
    "my_cols = low_cardinality_cols + numeric_cols\n",
    "X_train = X_train_full[my_cols].copy()\n",
    "X_valid = X_valid_full[my_cols].copy()\n",
    "\n",
    "# One-hot encode the data (to shorten the code, we use pandas)\n",
    "X_train = pd.get_dummies(X_train)\n",
    "X_valid = pd.get_dummies(X_valid)\n",
    "X_train, X_valid = X_train.align(X_valid, join='left', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "my_model = XGBRegressor(random_state=0)\n",
    "my_model.fit(X_train, y_train)\n",
    "# Predict\n",
    "prediction_1 = my_model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_dict['6.a'] = mean_absolute_error(y_valid, prediction_1)\n",
    "\n",
    "print(\"MAE (Gradient Boost):\") \n",
    "print(scores_dict['6.a'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the Submission for Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "low_cardinality_cols = [cname for cname in X.columns if X[cname].nunique() < 10 and \n",
    "                        X[cname].dtype == \"object\"]\n",
    "\n",
    "# Select numeric columns\n",
    "numeric_cols = [cname for cname in X.columns if X[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Keep selected columns only\n",
    "my_cols = low_cardinality_cols + numeric_cols\n",
    "X = X_full[my_cols].copy()\n",
    "X_test = X_test_full[my_cols].copy()\n",
    "\n",
    "# One-hot encode the data (to shorten the code, we use pandas)\n",
    "X = pd.get_dummies(X)\n",
    "X_test = pd.get_dummies(X_test)\n",
    "X, X_test = X.align(X_test, join='left', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = XGBRegressor(random_state=0)\n",
    "my_model.fit(X, y)\n",
    "test_prediction_6a = my_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the data together into an output and save it to submission.csv\n",
    "output = pd.DataFrame({'Id': test_X.index,\n",
    "                       'SalePrice': test_prediction_6a})\n",
    "submission_dict['6.a'] = test_prediction_6a\n",
    "print(\"XGBoost Submission Saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"subsec-6b\"></a>\n",
    "## Part 6.b XGBoost (Parameter Tuning)\n",
    "## Testing Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "low_cardinality_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and \n",
    "                        X_train_full[cname].dtype == \"object\"]\n",
    "\n",
    "# Select numeric columns\n",
    "numeric_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Keep selected columns only\n",
    "my_cols = low_cardinality_cols + numeric_cols\n",
    "\n",
    "X_train = X_train_full[my_cols].copy()\n",
    "X_valid = X_valid_full[my_cols].copy()\n",
    "\n",
    "\n",
    "# One-hot encode the data (to shorten the code, we use pandas)\n",
    "X_train = pd.get_dummies(X_train)\n",
    "X_valid = pd.get_dummies(X_valid)\n",
    "X_train, X_valid = X_train.align(X_valid, join='left', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "my_model_2 = XGBRegressor(n_estimators=500, learning_rate=0.05)\n",
    "\n",
    "# Fit the model\n",
    "my_model_2.fit(X_train, y_train,\n",
    "               early_stopping_rounds=5,\n",
    "               eval_set=[(X_valid, y_valid)],\n",
    "               verbose=False)\n",
    "               \n",
    "\n",
    "# Get predictions\n",
    "prediction_2 = my_model_2.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_dict['6.b'] = mean_absolute_error(y_valid, prediction_2)\n",
    "\n",
    "print(\"MAE (Parameter Tuning):\") \n",
    "print(scores_dict['6.b'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Submission using Parameter Tuning\n",
    "Unlike the other methods, parameter tuning requires a training set, a validation set, and a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "low_cardinality_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and \n",
    "                        X_train_full[cname].dtype == \"object\"]\n",
    "\n",
    "# Select numeric columns\n",
    "numeric_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Keep selected columns only\n",
    "my_cols = low_cardinality_cols + numeric_cols\n",
    "X_train = X_train_full[my_cols].copy()\n",
    "X_valid = X_valid_full[my_cols].copy()\n",
    "X_test = X_test_full[my_cols].copy()\n",
    "\n",
    "\n",
    "# One-hot encode the data (to shorten the code, we use pandas)\n",
    "X_train = pd.get_dummies(X_train)\n",
    "X_valid = pd.get_dummies(X_valid)\n",
    "X_test = pd.get_dummies(X_test)\n",
    "X_train, X_valid = X_train.align(X_valid, join='left', axis=1)\n",
    "X_train, X_test = X_train.align(X_test, join='left', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "my_model_3 = XGBRegressor(n_estimators=500, learning_rate=0.05)\n",
    "\n",
    "# Fit the model\n",
    "my_model_3.fit(X_train, y_train,\n",
    "               early_stopping_rounds=5,\n",
    "               eval_set=[(X_valid, y_valid)],\n",
    "               verbose=False)\n",
    "\n",
    "test_prediction_6b = my_model_3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the data together into an output and save it to submission.csv\n",
    "output = pd.DataFrame({'Id': test_X.index,\n",
    "                       'SalePrice': test_prediction_6b})\n",
    "submission_dict['6.b'] = test_prediction_6b\n",
    "print(\"Parameter Tuning Submission Saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec-7\"></a>\n",
    "# Part 7. Visualizations\n",
    "We will plot the housing prices data in a variety of ways to learn more about the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the paths to our data\n",
    "test_data_path = \"../input/house-prices-advanced-regression-techniques/test.csv\"\n",
    "train_data_path = \"../input/house-prices-advanced-regression-techniques/train.csv\"\n",
    "sample_data_path = \"../input/house-prices-advanced-regression-techniques/sample_submission.csv\"\n",
    "\n",
    "# Define the data\n",
    "test_data = pd.read_csv(test_data_path, index_col='Id')\n",
    "train_data = pd.read_csv(train_data_path, index_col='Id')\n",
    "sample_data = pd.read_csv(sample_data_path)\n",
    "\n",
    "# Define the plot style used\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"subsec-7a\"></a>\n",
    "## Part 7.a Analyzing \"SalePrice\"\n",
    "First thing we'll check out is how the main property of SalePrice changes in relation to other properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the sale price using the describe function\n",
    "train_data['SalePrice'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the sale price visually using a histogram\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.distplot(train_data['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the SalePrice is strongly peaked at ~15000 with a longer tail towards higher prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The documentation states that there are potential outliers in comparing\n",
    "# SalePrice and GrLivArea (Above grade (ground) living area square feet)\n",
    "# so lets see if that is true\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.scatterplot(x=train_data['GrLivArea'], y=train_data['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are some pretty extreme outliers out beyond GrLivArea > 4000 with SalePrice < 20000\n",
    "# Lets draw trend lines with these points and without to see their effect\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.regplot(x=train_data['GrLivArea'], y=train_data['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing those two data points\n",
    "high_GrLivArea = np.where(train_data['GrLivArea'] > 4000)[0]\n",
    "low_SalePrice = np.where(train_data['SalePrice'] < 200000)[0]\n",
    "\n",
    "print(\"high GrLivArea points: \", high_GrLivArea)\n",
    "print(\"\\nlow SalePrice points: \", low_SalePrice)\n",
    "\n",
    "outlier_inds = list(set(high_GrLivArea) & set(low_SalePrice))\n",
    "outlier_inds.sort()\n",
    "\n",
    "print(\"\\noutliers: \", outlier_inds)\n",
    "\n",
    "shortened_train_data = train_data.drop(train_data.index[outlier_inds])\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.regplot(x=shortened_train_data['GrLivArea'], y=shortened_train_data['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like removing the two outliers has reduced the spread of our trend and properly handling outliers should be an important step in the analysis. It's important to note that removing outliers is not always safe and should be done with caution. A safer option moving forward should be to make the machine learning model more robust to outliers. Unfortunately, I have not learned this skill yet from the courses so we will not be applying these techniques yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"subsec-7b\"></a>\n",
    "## Section 7.b Heatmaps of the Data\n",
    "There are too many columns of data to individually compare to the SalePrice. Here we will be using a heatmap to see how each property correlates to SalePrice using a Heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to generate a correlation matrix with our data\n",
    "correlation_matrix = train_data.corr()\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "sns.heatmap(correlation_matrix, square=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bottom row is the SalePrice and we can see which properties seem to correlates most strongly with it.\n",
    "1. OverallQual\n",
    "2. GrLivArea\n",
    "These two properties seem to be the strongly correlated but we can fiddle with heatmap properties to find the ones that are most relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "# look for the top 10 properties, need to pass number of properties we're\n",
    "# interested + 1 because SalePrice has a 1:1 correlation with itself\n",
    "num_variables = 11 \n",
    "\n",
    "top_cols = correlation_matrix.nlargest(num_variables, 'SalePrice')['SalePrice'].index\n",
    "short_cm = np.corrcoef(train_data[top_cols].values.T)\n",
    "\n",
    "sns.heatmap(short_cm, annot=True, yticklabels=top_cols.values, xticklabels=top_cols.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing this we can see in descending order the most important properties are:\n",
    "1. OverallQual: Rates the overall material and finish of the house\n",
    "2. GrLivArea: Above grade (ground) living area in square feet\n",
    "3. GarageCars: Size of garage in car capacity\n",
    "4. GarageArea: Size of garage in square feet\n",
    "5. TotalBsmtSF: Total square feet of basement area\n",
    "6. 1stFlrSF: First Floor square feet\n",
    "7. FullBath: Full bathrooms above grade\n",
    "8. TotRmsAbvGrd: Total rooms above grade (does not include bathrooms)\n",
    "9. YearBuilt: Original construction date\n",
    "10. YearRemodAdd: Remodel date (same as construction date if no remodeling or additions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In regards to this data we can draw some comparisons between some of them\n",
    "\n",
    "* GarageCars and GarageArea are effectively describing the same thing.\n",
    "* TotRmsAbvGrd and GrLivArea are similar and also describe the total space above ground\n",
    "* There is strong correlation between 1stFlrSF and TotalBsmtSF likely suggesting that if you have a large basement then you'll also have a large ground floor.\n",
    "* There is effectively no correlation between when the house was built and the total square ft of the home."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sec-8\"></a>\n",
    "# Part 8. Checking which method is best and saving to submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAE values generated:\")\n",
    "for i in scores_dict:\n",
    "    print(i + \" : \" + str(scores_dict[i]))\n",
    "    \n",
    "min_key = min(scores_dict, key=scores_dict.get)\n",
    "\n",
    "print(\"\\nMethod with lowest MAE:\")\n",
    "print(min_key)\n",
    "\n",
    "submission = submission_dict[min_key]\n",
    "# print(submission)\n",
    "\n",
    "output = pd.DataFrame({'Id': sample_data.Id,\n",
    "                       'SalePrice': submission})\n",
    "output.to_csv('submission.csv', index=False)\n",
    "print(\"\\nOutput generated as submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
